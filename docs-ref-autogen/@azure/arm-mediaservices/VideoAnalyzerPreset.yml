### YamlMime:UniversalReference
items:
  - uid: '@azure/arm-mediaservices.VideoAnalyzerPreset'
    name: VideoAnalyzerPreset
    fullName: VideoAnalyzerPreset
    children:
      - '@azure/arm-mediaservices.VideoAnalyzerPreset.audioLanguage'
      - '@azure/arm-mediaservices.VideoAnalyzerPreset.insightsToExtract'
      - '@azure/arm-mediaservices.VideoAnalyzerPreset.odatatype'
    langs:
      - typeScript
    type: interface
    summary: >-
      A video analyzer preset that extracts insights (rich metadata) from both
      audio and video, and

      outputs a JSON format file.
    package: '@azure/arm-mediaservices'
  - uid: '@azure/arm-mediaservices.VideoAnalyzerPreset.audioLanguage'
    name: audioLanguage
    fullName: audioLanguage
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The language for the audio payload in the input using the BCP-47 format of
      'language

      tag-region' (e.g: 'en-US').  The list of supported languages are English
      ('en-US' and

      'en-GB'), Spanish ('es-ES' and 'es-MX'), French ('fr-FR'), Italian
      ('it-IT'), Japanese

      ('ja-JP'), Portuguese ('pt-BR'), Chinese ('zh-CN'), German ('de-DE'),
      Arabic ('ar-EG' and

      'ar-SY'), Russian ('ru-RU'), Hindi ('hi-IN'), and Korean ('ko-KR'). If you
      know the language

      of your content, it is recommended that you specify it. If the language
      isn't specified or set

      to null, automatic language detection will choose the first language
      detected and process with

      the selected language for the duration of the file. This language
      detection feature currently

      supports English, Chinese, French, German, Italian, Japanese, Spanish,
      Russian, and

      Portuguese. It does not currently support dynamically switching between
      languages after the

      first language is detected. The automatic detection works best with audio
      recordings with

      clearly discernable speech. If automatic detection fails to find the
      language, transcription

      would fallback to 'en-US'."
    optional: true
    syntax:
      content: 'audioLanguage?: undefined | string'
      return:
        type:
          - undefined | string
    package: '@azure/arm-mediaservices'
  - uid: '@azure/arm-mediaservices.VideoAnalyzerPreset.insightsToExtract'
    name: insightsToExtract
    fullName: insightsToExtract
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The type of insights to be extracted. If not set then based on the content
      the type will

      selected.  If the content is audio only then only audio insights are
      extracted and if it is

      video only. Possible values include: 'AudioInsightsOnly',
      'VideoInsightsOnly', 'AllInsights'
    optional: true
    syntax:
      content: 'insightsToExtract?: InsightsType'
      return:
        type:
          - '@azure/arm-mediaservices.InsightsType'
    package: '@azure/arm-mediaservices'
  - uid: '@azure/arm-mediaservices.VideoAnalyzerPreset.odatatype'
    name: odatatype
    fullName: odatatype
    children: []
    langs:
      - typeScript
    type: property
    summary: Polymorphic Discriminator
    syntax:
      content: 'odatatype: "#Microsoft.Media.VideoAnalyzerPreset"'
      return:
        type:
          - '"#Microsoft.Media.VideoAnalyzerPreset"'
    package: '@azure/arm-mediaservices'
references:
  - uid: '@azure/arm-mediaservices.InsightsType'
    name: InsightsType
    spec.typeScript:
      - name: InsightsType
        fullName: InsightsType
        uid: '@azure/arm-mediaservices.InsightsType'
