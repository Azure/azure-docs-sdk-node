### YamlMime:UniversalReference
items:
  - uid: '@azure/search-documents.KnownTokenFilterNames'
    name: KnownTokenFilterNames
    fullName: KnownTokenFilterNames
    children:
      - '@azure/search-documents.KnownTokenFilterNames.Apostrophe'
      - '@azure/search-documents.KnownTokenFilterNames.ArabicNormalization'
      - '@azure/search-documents.KnownTokenFilterNames.AsciiFolding'
      - '@azure/search-documents.KnownTokenFilterNames.CjkBigram'
      - '@azure/search-documents.KnownTokenFilterNames.CjkWidth'
      - '@azure/search-documents.KnownTokenFilterNames.Classic'
      - '@azure/search-documents.KnownTokenFilterNames.CommonGram'
      - '@azure/search-documents.KnownTokenFilterNames.EdgeNGram'
      - '@azure/search-documents.KnownTokenFilterNames.Elision'
      - '@azure/search-documents.KnownTokenFilterNames.GermanNormalization'
      - '@azure/search-documents.KnownTokenFilterNames.HindiNormalization'
      - '@azure/search-documents.KnownTokenFilterNames.IndicNormalization'
      - '@azure/search-documents.KnownTokenFilterNames.KStem'
      - '@azure/search-documents.KnownTokenFilterNames.KeywordRepeat'
      - '@azure/search-documents.KnownTokenFilterNames.Length'
      - '@azure/search-documents.KnownTokenFilterNames.Limit'
      - '@azure/search-documents.KnownTokenFilterNames.Lowercase'
      - '@azure/search-documents.KnownTokenFilterNames.NGram'
      - '@azure/search-documents.KnownTokenFilterNames.PersianNormalization'
      - '@azure/search-documents.KnownTokenFilterNames.Phonetic'
      - '@azure/search-documents.KnownTokenFilterNames.PorterStem'
      - '@azure/search-documents.KnownTokenFilterNames.Reverse'
      - >-
        @azure/search-documents.KnownTokenFilterNames.ScandinavianFoldingNormalization
      - '@azure/search-documents.KnownTokenFilterNames.ScandinavianNormalization'
      - '@azure/search-documents.KnownTokenFilterNames.Shingle'
      - '@azure/search-documents.KnownTokenFilterNames.Snowball'
      - '@azure/search-documents.KnownTokenFilterNames.SoraniNormalization'
      - '@azure/search-documents.KnownTokenFilterNames.Stemmer'
      - '@azure/search-documents.KnownTokenFilterNames.Stopwords'
      - '@azure/search-documents.KnownTokenFilterNames.Trim'
      - '@azure/search-documents.KnownTokenFilterNames.Truncate'
      - '@azure/search-documents.KnownTokenFilterNames.Unique'
      - '@azure/search-documents.KnownTokenFilterNames.Uppercase'
      - '@azure/search-documents.KnownTokenFilterNames.WordDelimiter'
    langs:
      - typeScript
    type: enum
    summary: Defines values for TokenFilterName.
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Apostrophe'
    name: Apostrophe
    children: []
    langs:
      - typeScript
    summary: >-
      Strips all characters after an apostrophe (including the apostrophe
      itself). See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/tr/ApostropheFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.ArabicNormalization'
    name: ArabicNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      A token filter that applies the Arabic normalizer to normalize the
      orthography. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.AsciiFolding'
    name: AsciiFolding
    children: []
    langs:
      - typeScript
    summary: >-
      Converts alphabetic, numeric, and symbolic Unicode characters which are
      not in the first 127

      ASCII characters (the "Basic Latin" Unicode block) into their ASCII
      equivalents, if such

      equivalents exist. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.CjkBigram'
    name: CjkBigram
    children: []
    langs:
      - typeScript
    summary: >-
      Forms bigrams of CJK terms that are generated from StandardTokenizer. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/cjk/CJKBigramFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.CjkWidth'
    name: CjkWidth
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes CJK width differences. Folds fullwidth ASCII variants into the
      equivalent basic

      Latin, and half-width Katakana variants into the equivalent Kana. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/cjk/CJKWidthFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Classic'
    name: Classic
    children: []
    langs:
      - typeScript
    summary: >-
      Removes English possessives, and dots from acronyms. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/standard/ClassicFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.CommonGram'
    name: CommonGram
    children: []
    langs:
      - typeScript
    summary: >-
      Construct bigrams for frequently occurring terms while indexing. Single
      terms are still

      indexed too, with bigrams overlaid. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/commongrams/CommonGramsFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.EdgeNGram'
    name: EdgeNGram
    children: []
    langs:
      - typeScript
    summary: >-
      Generates n-grams of the given size(s) starting from the front or the back
      of an input token.

      See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Elision'
    name: Elision
    children: []
    langs:
      - typeScript
    summary: >-
      Removes elisions. For example, "l'avion" (the plane) will be converted to
      "avion" (plane). See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/util/ElisionFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.GermanNormalization'
    name: GermanNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes German characters according to the heuristics of the German2
      snowball algorithm.

      See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/de/GermanNormalizationFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.HindiNormalization'
    name: HindiNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes text in Hindi to remove some differences in spelling
      variations. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/hi/HindiNormalizationFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.IndicNormalization'
    name: IndicNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes the Unicode representation of text in Indian languages. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/in/IndicNormalizationFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.KStem'
    name: KStem
    children: []
    langs:
      - typeScript
    summary: >-
      A high-performance kstem filter for English. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/en/KStemFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.KeywordRepeat'
    name: KeywordRepeat
    children: []
    langs:
      - typeScript
    summary: >-
      Emits each incoming token twice, once as keyword and once as non-keyword.
      See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/KeywordRepeatFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Length'
    name: Length
    children: []
    langs:
      - typeScript
    summary: >-
      Removes words that are too long or too short. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/LengthFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Limit'
    name: Limit
    children: []
    langs:
      - typeScript
    summary: >-
      Limits the number of tokens while indexing. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Lowercase'
    name: Lowercase
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes token text to lower case. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/LowerCaseFilter.htm
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.NGram'
    name: NGram
    children: []
    langs:
      - typeScript
    summary: >-
      Generates n-grams of the given size(s). See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ngram/NGramTokenFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.PersianNormalization'
    name: PersianNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      Applies normalization for Persian. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/fa/PersianNormalizationFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Phonetic'
    name: Phonetic
    children: []
    langs:
      - typeScript
    summary: >-
      Create tokens for phonetic matches. See

      https://lucene.apache.org/core/4_10_3/analyzers-phonetic/org/apache/lucene/analysis/phonetic/package-tree.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.PorterStem'
    name: PorterStem
    children: []
    langs:
      - typeScript
    summary: |-
      Uses the Porter stemming algorithm to transform the token stream. See
      http://tartarus.org/~martin/PorterStemmer
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Reverse'
    name: Reverse
    children: []
    langs:
      - typeScript
    summary: >-
      Reverses the token string. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/reverse/ReverseStringFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: >-
      @azure/search-documents.KnownTokenFilterNames.ScandinavianFoldingNormalization
    name: ScandinavianFoldingNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      Folds Scandinavian characters åÅäæÄÆ-&gt;a and öÖøØ-&gt;o. It also
      discriminates against use

      of double vowels aa, ae, ao, oe and oo, leaving just the first one. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/ScandinavianFoldingFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.ScandinavianNormalization'
    name: ScandinavianNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes use of the interchangeable Scandinavian characters. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/ScandinavianNormalizationFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Shingle'
    name: Shingle
    children: []
    langs:
      - typeScript
    summary: >-
      Creates combinations of tokens as a single token. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/shingle/ShingleFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Snowball'
    name: Snowball
    children: []
    langs:
      - typeScript
    summary: >-
      A filter that stems words using a Snowball-generated stemmer. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/snowball/SnowballFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.SoraniNormalization'
    name: SoraniNormalization
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes the Unicode representation of Sorani text. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ckb/SoraniNormalizationFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Stemmer'
    name: Stemmer
    children: []
    langs:
      - typeScript
    summary: >-
      Language specific stemming filter. See

      https://docs.microsoft.com/rest/api/searchservice/Custom-analyzers-in-Azure-Search#TokenFilters
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Stopwords'
    name: Stopwords
    children: []
    langs:
      - typeScript
    summary: >-
      Removes stop words from a token stream. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/StopFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Trim'
    name: Trim
    children: []
    langs:
      - typeScript
    summary: >-
      Trims leading and trailing whitespace from tokens. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/TrimFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Truncate'
    name: Truncate
    children: []
    langs:
      - typeScript
    summary: >-
      Truncates the terms to a specific length. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/TruncateTokenFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Unique'
    name: Unique
    children: []
    langs:
      - typeScript
    summary: >-
      Filters out tokens with same text as the previous token. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.Uppercase'
    name: Uppercase
    children: []
    langs:
      - typeScript
    summary: >-
      Normalizes token text to upper case. See

      http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/core/UpperCaseFilter.html
    type: field
    numericValue: null
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.KnownTokenFilterNames.WordDelimiter'
    name: WordDelimiter
    children: []
    langs:
      - typeScript
    summary: >-
      Splits words into subwords and performs optional transformations on
      subword groups.
    type: field
    numericValue: null
    package: '@azure/search-documents'
