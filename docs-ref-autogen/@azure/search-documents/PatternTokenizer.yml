### YamlMime:UniversalReference
items:
  - uid: '@azure/search-documents.PatternTokenizer'
    name: PatternTokenizer
    fullName: PatternTokenizer
    children:
      - '@azure/search-documents.PatternTokenizer.flags'
      - '@azure/search-documents.PatternTokenizer.group'
      - '@azure/search-documents.PatternTokenizer.name'
      - '@azure/search-documents.PatternTokenizer.odatatype'
      - '@azure/search-documents.PatternTokenizer.pattern'
    langs:
      - typeScript
    type: interface
    summary: >-
      Tokenizer that uses regex pattern matching to construct distinct tokens.
      This tokenizer is

      implemented using Apache Lucene.
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.PatternTokenizer.flags'
    name: flags
    fullName: flags
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      Regular expression flags. Possible values include: 'CANON_EQ',
      'CASE_INSENSITIVE', 'COMMENTS',

      'DOTALL', 'LITERAL', 'MULTILINE', 'UNICODE_CASE', 'UNIX_LINES'
    optional: true
    syntax:
      content: 'flags?: RegexFlags[]'
      return:
        type:
          - '@azure/search-documents.RegexFlags[]'
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.PatternTokenizer.group'
    name: group
    fullName: group
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The zero-based ordinal of the matching group in the regular expression
      pattern to extract into

      tokens. Use -1 if you want to use the entire pattern to split the input
      into tokens,

      irrespective of matching groups. Default is -1. Default value: -1.
    optional: true
    syntax:
      content: 'group?: number'
      return:
        type:
          - number
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.PatternTokenizer.name'
    name: name
    fullName: name
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The name of the tokenizer. It must only contain letters, digits, spaces,
      dashes or

      underscores, can only start and end with alphanumeric characters, and is
      limited to 128

      characters.
    syntax:
      content: 'name: string'
      return:
        type:
          - string
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.PatternTokenizer.odatatype'
    name: odatatype
    fullName: odatatype
    children: []
    langs:
      - typeScript
    type: property
    summary: Polymorphic Discriminator
    syntax:
      content: 'odatatype: "#Microsoft.Azure.Search.PatternTokenizer"'
      return:
        type:
          - '"#Microsoft.Azure.Search.PatternTokenizer"'
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.PatternTokenizer.pattern'
    name: pattern
    fullName: pattern
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      A regular expression pattern to match token separators. Default is an
      expression that matches

      one or more whitespace characters. Default value: '\W+'.
    optional: true
    syntax:
      content: 'pattern?: string'
      return:
        type:
          - string
        description: ''
    package: '@azure/search-documents'
references:
  - uid: '@azure/search-documents.RegexFlags[]'
    name: 'RegexFlags[]'
    spec.typeScript:
      - name: RegexFlags
        fullName: RegexFlags
        uid: '@azure/search-documents.RegexFlags'
      - name: '[]'
        fullName: '[]'
