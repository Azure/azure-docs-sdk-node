### YamlMime:UniversalReference
items:
  - uid: '@azure/search-documents.NGramTokenizer'
    name: NGramTokenizer
    fullName: NGramTokenizer
    children:
      - '@azure/search-documents.NGramTokenizer.maxGram'
      - '@azure/search-documents.NGramTokenizer.minGram'
      - '@azure/search-documents.NGramTokenizer.name'
      - '@azure/search-documents.NGramTokenizer.odatatype'
      - '@azure/search-documents.NGramTokenizer.tokenChars'
    langs:
      - typeScript
    type: interface
    summary: >-
      Tokenizes the input into n-grams of the given size(s). This tokenizer is
      implemented using

      Apache Lucene.
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.NGramTokenizer.maxGram'
    name: maxGram
    fullName: maxGram
    children: []
    langs:
      - typeScript
    type: property
    summary: 'The maximum n-gram length. Default is 2. Maximum is 300. Default value: 2.'
    optional: true
    syntax:
      content: 'maxGram?: number'
      return:
        type:
          - number
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.NGramTokenizer.minGram'
    name: minGram
    fullName: minGram
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The minimum n-gram length. Default is 1. Maximum is 300. Must be less than
      the value of

      maxGram. Default value: 1.
    optional: true
    syntax:
      content: 'minGram?: number'
      return:
        type:
          - number
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.NGramTokenizer.name'
    name: name
    fullName: name
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The name of the tokenizer. It must only contain letters, digits, spaces,
      dashes or

      underscores, can only start and end with alphanumeric characters, and is
      limited to 128

      characters.
    syntax:
      content: 'name: string'
      return:
        type:
          - string
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.NGramTokenizer.odatatype'
    name: odatatype
    fullName: odatatype
    children: []
    langs:
      - typeScript
    type: property
    summary: Polymorphic Discriminator
    syntax:
      content: 'odatatype: "#Microsoft.Azure.Search.NGramTokenizer"'
      return:
        type:
          - '"#Microsoft.Azure.Search.NGramTokenizer"'
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.NGramTokenizer.tokenChars'
    name: tokenChars
    fullName: tokenChars
    children: []
    langs:
      - typeScript
    type: property
    summary: Character classes to keep in the tokens.
    optional: true
    syntax:
      content: 'tokenChars?: TokenCharacterKind[]'
      return:
        type:
          - '@azure/search-documents.TokenCharacterKind[]'
        description: ''
    package: '@azure/search-documents'
references:
  - uid: '@azure/search-documents.TokenCharacterKind[]'
    name: 'TokenCharacterKind[]'
    spec.typeScript:
      - name: TokenCharacterKind
        fullName: TokenCharacterKind
        uid: '@azure/search-documents.TokenCharacterKind'
      - name: '[]'
        fullName: '[]'
