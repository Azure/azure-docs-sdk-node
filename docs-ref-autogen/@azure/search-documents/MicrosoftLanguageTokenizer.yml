### YamlMime:UniversalReference
items:
  - uid: '@azure/search-documents.MicrosoftLanguageTokenizer'
    name: MicrosoftLanguageTokenizer
    fullName: MicrosoftLanguageTokenizer
    children:
      - '@azure/search-documents.MicrosoftLanguageTokenizer.isSearchTokenizer'
      - '@azure/search-documents.MicrosoftLanguageTokenizer.language'
      - '@azure/search-documents.MicrosoftLanguageTokenizer.maxTokenLength'
      - '@azure/search-documents.MicrosoftLanguageTokenizer.name'
      - '@azure/search-documents.MicrosoftLanguageTokenizer.odatatype'
    langs:
      - typeScript
    type: interface
    summary: Divides text using language-specific rules.
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageTokenizer.isSearchTokenizer'
    name: isSearchTokenizer
    fullName: isSearchTokenizer
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      A value indicating how the tokenizer is used. Set to true if used as the
      search tokenizer, set

      to false if used as the indexing tokenizer. Default is false. Default
      value: false.
    optional: true
    syntax:
      content: 'isSearchTokenizer?: boolean'
      return:
        type:
          - boolean
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageTokenizer.language'
    name: language
    fullName: language
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The language to use. The default is English. Possible values include:
      'Bangla', 'Bulgarian',

      'Catalan', 'ChineseSimplified', 'ChineseTraditional', 'Croatian', 'Czech',
      'Danish', 'Dutch',

      'English', 'French', 'German', 'Greek', 'Gujarati', 'Hindi', 'Icelandic',
      'Indonesian',

      'Italian', 'Japanese', 'Kannada', 'Korean', 'Malay', 'Malayalam',
      'Marathi',

      'NorwegianBokmaal', 'Polish', 'Portuguese', 'PortugueseBrazilian',
      'Punjabi', 'Romanian',

      'Russian', 'SerbianCyrillic', 'SerbianLatin', 'Slovenian', 'Spanish',
      'Swedish', 'Tamil',

      'Telugu', 'Thai', 'Ukrainian', 'Urdu', 'Vietnamese'
    optional: true
    syntax:
      content: 'language?: MicrosoftTokenizerLanguage'
      return:
        type:
          - '@azure/search-documents.MicrosoftTokenizerLanguage'
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageTokenizer.maxTokenLength'
    name: maxTokenLength
    fullName: maxTokenLength
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The maximum token length. Tokens longer than the maximum length are split.
      Maximum token

      length that can be used is 300 characters. Tokens longer than 300
      characters are first split

      into tokens of length 300 and then each of those tokens is split based on
      the max token length

      set. Default is 255. Default value: 255.
    optional: true
    syntax:
      content: 'maxTokenLength?: number'
      return:
        type:
          - number
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageTokenizer.name'
    name: name
    fullName: name
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The name of the tokenizer. It must only contain letters, digits, spaces,
      dashes or

      underscores, can only start and end with alphanumeric characters, and is
      limited to 128

      characters.
    syntax:
      content: 'name: string'
      return:
        type:
          - string
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageTokenizer.odatatype'
    name: odatatype
    fullName: odatatype
    children: []
    langs:
      - typeScript
    type: property
    summary: Polymorphic Discriminator
    syntax:
      content: 'odatatype: "#Microsoft.Azure.Search.MicrosoftLanguageTokenizer"'
      return:
        type:
          - '"#Microsoft.Azure.Search.MicrosoftLanguageTokenizer"'
        description: ''
    package: '@azure/search-documents'
references:
  - uid: '@azure/search-documents.MicrosoftTokenizerLanguage'
    name: MicrosoftTokenizerLanguage
    spec.typeScript:
      - name: MicrosoftTokenizerLanguage
        fullName: MicrosoftTokenizerLanguage
        uid: '@azure/search-documents.MicrosoftTokenizerLanguage'
