### YamlMime:UniversalReference
items:
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient
    name: ComputerVisionClient
    fullName: ComputerVisionClient
    children:
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.constructor
      - azure-cognitiveservices-computervision.ComputerVisionClient.credentials
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    langs:
      - typeScript
    type: class
    summary: ''
    extends:
      name: ServiceClient
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
    name: 'analyzeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: 'function analyzeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
    name: 'analyzeImage(string, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: >-
        function analyzeImage(url: string, options: Object, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
    name: 'analyzeImage(string, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: >-
        function analyzeImage(url: string, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
    name: 'analyzeImageByDomain(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, options?:
        Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
    name: >-
      analyzeImageByDomain(string, string, Object,
      ServiceCallback<DomainModelResults>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, options:
        Object, callback: ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
    name: 'analyzeImageByDomain(string, string, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, callback:
        ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, options?: Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
    name: >-
      analyzeImageByDomainInStream(string, stream.Readable, Object,
      ServiceCallback<DomainModelResults>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, options: Object, callback:
        ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
    name: >-
      analyzeImageByDomainInStream(string, stream.Readable,
      ServiceCallback<DomainModelResults>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, callback: ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
    name: >-
      analyzeImageByDomainInStreamWithHttpOperationResponse(string,
      stream.Readable, Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStreamWithHttpOperationResponse(model:
        string, image: stream.Readable, options?: Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
    name: 'analyzeImageByDomainWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainWithHttpOperationResponse(model: string,
        url: string, options?: Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
    name: 'analyzeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
    name: >-
      analyzeImageInStream(stream.Readable, Object,
      ServiceCallback<ImageAnalysis>)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: >-
        function analyzeImageInStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<ImageAnalysis>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
    name: 'analyzeImageInStream(stream.Readable, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: >-
        function analyzeImageInStream(image: stream.Readable, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
    name: 'analyzeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: >-
        function analyzeImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
    name: 'analyzeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: >-
        function analyzeImageWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.constructor
    name: >-
      ComputerVisionClient(ServiceClientCredentials, string,
      ServiceClientOptions)
    children: []
    type: constructor
    langs:
      - typeScript
    summary: ''
    syntax:
      content: >-
        new ComputerVisionClient(credentials: ServiceClientCredentials,
        endpoint: string, options?: ServiceClientOptions)
      parameters:
        - id: credentials
          type:
            - ServiceClientCredentials
          description: >
            Subscription credentials which uniquely identify client
            subscription.
        - id: endpoint
          type:
            - string
          description: |
            Supported Cognitive Services endpoints
        - id: options
          type:
            - ServiceClientOptions
          description: ''
          optional: true
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.credentials
    name: credentials
    fullName: credentials
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'credentials: ServiceClientCredentials'
      return:
        type:
          - ServiceClientCredentials
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
    name: 'describeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function describeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
    name: 'describeImage(string, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImage(url: string, options: Object, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
    name: 'describeImage(string, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImage(url: string, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
    name: 'describeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
    name: >-
      describeImageInStream(stream.Readable, Object,
      ServiceCallback<ImageDescription>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<ImageDescription>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
    name: 'describeImageInStream(stream.Readable, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStream(image: stream.Readable, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
    name: 'describeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
    name: 'describeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
    name: endpoint
    fullName: endpoint
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'endpoint: string'
      return:
        type:
          - string
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
    name: 'generateThumbnail(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
    name: >-
      generateThumbnail(number, number, string, Object,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        options: Object, callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
    name: >-
      generateThumbnail(number, number, string,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
    name: >-
      generateThumbnailInStream(number, number, stream.Readable, Object,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, options: Object, callback:
        ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
    name: >-
      generateThumbnailInStream(number, number, stream.Readable,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
    name: >-
      generateThumbnailInStreamWithHttpOperationResponse(number, number,
      stream.Readable, Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStreamWithHttpOperationResponse(width:
        number, height: number, image: stream.Readable, options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
    name: 'generateThumbnailWithHttpOperationResponse(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailWithHttpOperationResponse(width: number,
        height: number, url: string, options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
    name: 'getTextOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: 'function getTextOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of the text operation returned in the
            response of the 'Recognize Text'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
    name: >-
      getTextOperationResult(string, Object,
      ServiceCallback<TextOperationResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResult(operationId: string, options: Object,
        callback: ServiceCallback<TextOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
    name: 'getTextOperationResult(string, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResult(operationId: string, callback:
        ServiceCallback<TextOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
    name: 'getTextOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResultWithHttpOperationResponse(operationId:
        string, options?: Object)
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of the text operation returned in the
            response of the 'Recognize Text'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels
    name: listModels(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: 'function listModels(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
    name: 'listModels(Object, ServiceCallback<ListModelsResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: >-
        function listModels(options: Object, callback:
        ServiceCallback<ListModelsResult>)
      parameters:
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
    name: listModels(ServiceCallback<ListModelsResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
    name: listModelsWithHttpOperationResponse(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: 'function listModelsWithHttpOperationResponse(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
    name: 'recognizePrintedText(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
    name: 'recognizePrintedText(boolean, string, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        options: Object, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
    name: 'recognizePrintedText(boolean, string, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
    name: >-
      recognizePrintedTextInStream(boolean, stream.Readable, Object,
      ServiceCallback<OcrResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, options: Object, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
    name: >-
      recognizePrintedTextInStream(boolean, stream.Readable,
      ServiceCallback<OcrResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
    name: >-
      recognizePrintedTextInStreamWithHttpOperationResponse(boolean,
      stream.Readable, Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function
        recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation:
        boolean, image: stream.Readable, options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
    name: 'recognizePrintedTextWithHttpOperationResponse(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function
        recognizePrintedTextWithHttpOperationResponse(detectOrientation:
        boolean, url: string, options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
    name: 'recognizeText(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: 'function recognizeText(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
    name: 'recognizeText(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeText(url: string, mode: string, options: Object,
        callback: ServiceCallback<void>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
    name: 'recognizeText(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeText(url: string, mode: string, callback:
        ServiceCallback<void>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
    name: 'recognizeTextInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, mode: string,
        options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
    name: >-
      recognizeTextInStream(stream.Readable, string, Object,
      ServiceCallback<void>)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, mode: string,
        options: Object, callback: ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
    name: 'recognizeTextInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, mode: string,
        callback: ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
    name: >-
      recognizeTextInStreamWithHttpOperationResponse(stream.Readable, string,
      Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStreamWithHttpOperationResponse(image:
        stream.Readable, mode: string, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
    name: 'recognizeTextWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextWithHttpOperationResponse(url: string, mode:
        string, options?: Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
    name: 'tagImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: 'function tagImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
    name: 'tagImage(string, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: >-
        function tagImage(url: string, options: Object, callback:
        ServiceCallback<TagResult>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
    name: 'tagImage(string, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
    name: 'tagImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
    name: 'tagImageInStream(stream.Readable, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: >-
        function tagImageInStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<TagResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
    name: 'tagImageInStream(stream.Readable, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: >-
        function tagImageInStream(image: stream.Readable, callback:
        ServiceCallback<TagResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
    name: 'tagImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: >-
        function tagImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    name: 'tagImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag 'cello'
      may

      be accompanied by the hint 'musical instrument'. All tags are in English.
    syntax:
      content: >-
        function tagImageWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
references:
  - uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    name: DomainModelResults>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>>'
        fullName: '>>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    name: ImageAnalysis>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    name: ImageDescription>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    name: TextOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    name: ListModelsResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    name: OcrResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    name: TagResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>>'
        fullName: '>>'
