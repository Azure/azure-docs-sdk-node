### YamlMime:UniversalReference
items:
  - uid: '@azure/search-documents.MicrosoftLanguageStemmingTokenizer'
    name: MicrosoftLanguageStemmingTokenizer
    fullName: MicrosoftLanguageStemmingTokenizer
    children:
      - >-
        @azure/search-documents.MicrosoftLanguageStemmingTokenizer.isSearchTokenizer
      - '@azure/search-documents.MicrosoftLanguageStemmingTokenizer.language'
      - >-
        @azure/search-documents.MicrosoftLanguageStemmingTokenizer.maxTokenLength
      - '@azure/search-documents.MicrosoftLanguageStemmingTokenizer.name'
      - '@azure/search-documents.MicrosoftLanguageStemmingTokenizer.odatatype'
    langs:
      - typeScript
    type: interface
    summary: >-
      Divides text using language-specific rules and reduces words to their base
      forms.
    package: '@azure/search-documents'
  - uid: >-
      @azure/search-documents.MicrosoftLanguageStemmingTokenizer.isSearchTokenizer
    name: isSearchTokenizer
    fullName: isSearchTokenizer
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      A value indicating how the tokenizer is used. Set to true if used as the
      search tokenizer, set

      to false if used as the indexing tokenizer. Default is false. Default
      value: false.
    optional: true
    syntax:
      content: 'isSearchTokenizer?: boolean'
      return:
        type:
          - boolean
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageStemmingTokenizer.language'
    name: language
    fullName: language
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The language to use. The default is English. Possible values include:
      'arabic', 'bangla',

      'bulgarian', 'catalan', 'croatian', 'czech', 'danish', 'dutch', 'english',
      'estonian',

      'finnish', 'french', 'german', 'greek', 'gujarati', 'hebrew', 'hindi',
      'hungarian',

      'icelandic', 'indonesian', 'italian', 'kannada', 'latvian', 'lithuanian',
      'malay',

      'malayalam', 'marathi', 'norwegianBokmaal', 'polish', 'portuguese',
      'portugueseBrazilian',

      'punjabi', 'romanian', 'russian', 'serbianCyrillic', 'serbianLatin',
      'slovak', 'slovenian',

      'spanish', 'swedish', 'tamil', 'telugu', 'turkish', 'ukrainian', 'urdu'
    optional: true
    syntax:
      content: 'language?: MicrosoftStemmingTokenizerLanguage'
      return:
        type:
          - '@azure/search-documents.MicrosoftStemmingTokenizerLanguage'
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageStemmingTokenizer.maxTokenLength'
    name: maxTokenLength
    fullName: maxTokenLength
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The maximum token length. Tokens longer than the maximum length are split.
      Maximum token

      length that can be used is 300 characters. Tokens longer than 300
      characters are first split

      into tokens of length 300 and then each of those tokens is split based on
      the max token length

      set. Default is 255. Default value: 255.
    optional: true
    syntax:
      content: 'maxTokenLength?: number'
      return:
        type:
          - number
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageStemmingTokenizer.name'
    name: name
    fullName: name
    children: []
    langs:
      - typeScript
    type: property
    summary: >-
      The name of the tokenizer. It must only contain letters, digits, spaces,
      dashes or

      underscores, can only start and end with alphanumeric characters, and is
      limited to 128

      characters.
    syntax:
      content: 'name: string'
      return:
        type:
          - string
        description: ''
    package: '@azure/search-documents'
  - uid: '@azure/search-documents.MicrosoftLanguageStemmingTokenizer.odatatype'
    name: odatatype
    fullName: odatatype
    children: []
    langs:
      - typeScript
    type: property
    summary: Polymorphic Discriminator
    syntax:
      content: 'odatatype: "#Microsoft.Azure.Search.MicrosoftLanguageStemmingTokenizer"'
      return:
        type:
          - '"#Microsoft.Azure.Search.MicrosoftLanguageStemmingTokenizer"'
        description: ''
    package: '@azure/search-documents'
references:
  - uid: '@azure/search-documents.MicrosoftStemmingTokenizerLanguage'
    name: MicrosoftStemmingTokenizerLanguage
    spec.typeScript:
      - name: MicrosoftStemmingTokenizerLanguage
        fullName: MicrosoftStemmingTokenizerLanguage
        uid: '@azure/search-documents.MicrosoftStemmingTokenizerLanguage'
